<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=windows-1252">
    <title>Vision De-Sign</title>
    <link rel="stylesheet" type="text/css" href="estilos.css">
  </head>
  <body> 
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <header id="main-header">
      <p class="logo"> <img src="images/logo_black.PNG" alt="" style="height: 110px"></p>
      <div class="tab"> <button class="tablinks" onclick="openCity(event, 'proyect')">
          Proyect </button> <button class="tablinks" onclick="openCity(event, 'team')">
          Team </button> <button class="tablinks" onclick="openCity(event, 'achievement')">
          Achievement </button> <button class="tablinks" onclick="openCity(event, 'about')">
          Credit </button> </div>
    </header>
    <div id="proyect" class="tabcontent" ;="">
      <h3>Project</h3>
      <p class="articles"> <br>
        The Visio De-sign project is a work developed by four people to the
        subject “Computer Vision”, from the Automatics and Robotics Master’s
        degree in Universidad Politécnica de Madrid. And, what’s it about?
        Well,… the field and goal could have been almost anything, but in our
        case, we have decided to focus on street signs recognition, mainly due
        to two factors: </p>
      <ul class="articles">
        <li style="max-width:40%; float:left">
          <p> The first one is just about current technology and developments in
            the personal vehicle industry: we need cars, among others, to be
            smarter each day, being capable of extract information from the
            environment and understand it like a human does. </p>
          <img src="images/no_driver.png" alt="no_driver" style="padding: 20px; width:375px; height:275px; margin-left: 10%">
        </li>
        <li style="max-width:40%; float:right; margin-right: 45px">
          <p> The second one is personal: since we are tired of answering sign
            related captcha, it would be interesting that the entity who press
            the “I am not a robot” button is actually a robot. </p>
          <img src="images/no_robot.png" alt="no_robot" style="padding: 20px; height:350px; width:315px; margin-left: 25%">
        </li>
      </ul>
      <div style="margin-top: 550px;"> <img src="images/sign_straight_up.jpg" alt="sign_straight_up"

          class="left_photos" style="max-width:15%; padding: 20px; margin-top:80px; margin-bottom:40px; ">
        <img src="images/sign_straight.jpg" alt="sign_straight2" class="right_photos"

          style="max-width:15%;padding: 20px; margin-top:80px; margin-bottom:40px">
        <p class="articles" style="max-width:80%; margin-left: 285px; margin-right: 285px">
          Nowadays, with a huge number of vehicles sharing the roads and a
          technology that allow the machines to be faster each day, the security
          is undeniably an important matter in the transport industry. Thus,
          advanced technology is constantly designed to include new
          security-related features, and one of them is the automatic traffic
          sign detection and recognition (ATSDR), that allows the machine to
          identify traffic sign along its way and perform actions in
          consequence. A vehicle which knows the speed limitations, for
          instance, is not only a good approach to persuade drivers from being
          risky by popping warnings, but also an opportunity to develop secure
          autonomous vehicles. There is indeed hard work on this last topic, and
          important companies around the globe are investing high budgets
          towards its development, because it can be understood as a first step
          in machine interaction with the human world in dangerous tasks, and it
          opens a new area of possibilities in transport. This interest is not,
          however, fortuitous. The first factor could be the modern computers,
          made with powerful microprocessors (CPU’s), high amount of flash
          memory (RAM) and high performance in parallel computing (GPU’s), which
          have provided the informatic power needed to run more and more complex
          algorithms. Because of that, interesting ideas from the past century
          in the AI field have increased both its scale and usefulness in the
          recent decades, being the deep neural networks the stars today.
          Besides, the high-quality hardware (cameras with high resolution,
          sensors, batteries, …) and programming tools make it possible for a
          company to develop a high-end detector, obtaining the return of their
          investment, and being seen, in marketing terms, as a modern and
          updated company. </p>
      </div>
      <br>
      <hr>
      <h4> State of Art </h4>
      <div>
        <p class="articles"> As we said before, there is a deep work in this,
          with more than 600 scientific articles published in the last decade,
          and 5400 citations, with a growing number of publications per year.
          For the work, we present this State of Art, made from research through
          diverse review articles and its sources.</p>
        <h4 style="font-size:17px"> Sign detection and recognition algorithm
          basics</h4>
        <div> <img src="images/detection.png" alt="signal detected" class="achievement_photos_right"

            style="padding:15px; margin-left:30px; margin-right:50px;">
          <p class="articles" style="margin-left:50px"> Basically, an ATSDR
            system consists on the application of six main steps: the image
            acquisition, where the system catches the scene that is going to be
            analyzed; the segmentation, a step that involves the region of
            interest localization; the shape detection, to find out whether the
            image contains geometrical shapes typically used in traffic signs;
            the recognition, which is the actual sign identification from the
            region; the tracking, to make it easier to locate signs already
            detected in an image sequence; and the display unit, which simply
            show the algorithm results. However, literature typically works with
            its own rules. For instance, the tracking analysis, which plays a
            role in an upper layer, is different from the solution of a single
            image and not commonly considered. Another example is the image
            acquisition, which is not a recurrent topic because algorithm
            development uses well-defined datasets in order to normalize the
            conditions to measure performance. Specifically, this measurement is
            based on the successful recognition rate over a huge number of
            images, provided that the dataset contains its own solution.</p>
        </div>
        <br>
        <div style="margin-top:50px"> <img src="images/fuzzy_sign.jpg" alt="fuzzy_sign"

            class="achievement_photos_left" style="padding:15px; margin-right:30px;">
          <p class="articles" style="bottom-margin: 80px; margin-right:70px;">
            This rate is the main criteria that classify the algorithms, and
            although its successfulness cannot be always extrapolated to any
            image, it shows how well an algorithm can face the typical problems
            on the images: color fading, due to the aging of the materials the
            signs are made of; similar signs, that are not easily distinguished;
            motion phenomena such as blur or vibrations when the image was
            caught; shadows, which hide important information; and above all,
            street objects with similar colors, a problem that can make a sign
            invisible for the algorithm or detect a fake sign instead. Some of
            the most common datasets used to these measures are the GermanTS
            dataset, the BelgiumTS dataset, and the FleyehTS dataset, among
            others, and they are indeed split into smaller packages with
            specific purposes: detection testing or recognition testing (usually
            annotated, they contain their solution).</p>
        </div>
        <h4 style="font-size:17px; margin-top:120px"> Detection algorithms</h4>
        <div> <img src="images/group_signs.jpg" alt="group_signs" class="achievement_photos_right"

            style="padding:15px; margin-left:30px; margin-right:50px;">
          <p class="articles" style="margin-left:50px"> This stage in the
            process is important, because signal recognition algorithms usually
            cannot distinguish a fake input and will assign the most similar
            sign whatever the fed image is. Hence, despite being the most
            complex part, this algorithm is the actual key to reach high
            performances. In this very problem, luckily, there are some
            advantages in detection, and the most important one is the fact that
            signs are designed to be easily seen by people, so they are usually
            painted with vivid colors (red, blue, yellow) and made with specific
            shapes (circles, triangles, hexagons). Therefore, the main
            algorithms simply take advantage of this. The first group, usually
            called the Color-based methods, seek for
            contrasting-from-the-background elements. Their main advantage is
            their robustness and low computing cost, but its algorithms are
            limited not only to colored images, which require a higher memory in
            terms of RAM and storage, but also to colorful images, since any
            phenomena involving color loss (rain, fog, material aging) shall
            result in failure.<br>
            <br>
            <br>
            These algorithms are based on the use of regions, to attach to them
            pixels that shares a specific characteristic, and the most used are
            the following:</p>
          <img src="images/alg_color.png" alt="alg_color" class="achievement_photos_left"

            style="padding:15px; margin-left:35px; margin-right:50px; margin-top:8px; vertical-align:center;">
          <ul class="articles" style="max-width:65%; margin-left:470px">
            <li>
              <p> Color thresholding: it assumes that neighbor pixels belong to
                the same object if their color values are within a specific
                tolerance. </p>
            </li>
            <li>
              <p> Region growing: the algorithm uses a seed coordinates to start
                a region out of a specific pixel. From it, some criteria are
                used in order to select similar surrounding pixels and make the
                region grow step by step.</p>
            </li>
            <li>
              <p> Color indexing: this algorithm compares two images from their
                color histogram and is used to find a sample image within
                another.</p>
            </li>
            <li>
              <p> Dynamic pixel aggregation: this method uses a variable
                tolerance while in the process of attaching pixels to a region
                and provides a higher performance in cases involving hue
                problems.</p>
            </li>
            <li>
              <p> CIECAM97: an algorithm based on a color transformation, and
                the use of the CIE XYZ space to normalize images taken in
                different lightning conditions.</p>
            </li>
          </ul>
        </div>
        <h4 style="font-size:17px; "> Recognition algorithms</h4>
        <div>
          <p class="articles" style="margin-left:50px"> In this case, once a
            group of pixels are supposed to contain a sign, the algorithm must
            figure out what sign actually is. This operation does not longer use
            direct information, such as shape or color, but a group of specific
            features that are not indeed always known. <br>
            The most used algorithms to accomplish this task are described
            below:</p>
          <img src="i%09mages/rec_alg.jpg" alt="rec_alg" class="achievement_photos_left"

            style="padding:15px; margin-left:35px; margin-right:20px; margin-top:60px; width:270px;">
          <ul class="articles" style="max-width:65%; margin-left:370px">
            <li>
              <p> Neural network: being the most important method of
                recognition, the performance of neural networks is high. Even
                the simple scheme is useful, because of its speed, the
                possibility to both detect and classify signs simultaneously
                with no speed loss and the modern hardware, specialized un
                parallel computing. However, the training stage is difficult,
                and may need a huge number of images to obtain a reliable
                system. That is why, in the recent years, the actual development
                is oriented towards deep learning, and specifically to
                convolutional neural networks (CNN). </p>
            </li>
            <li>
              <p> Adaptative boost classifier: it consists on the sum of many
                simple classifiers, which form a higher and more complex
                structure, fast and computationally reasonable. Nevertheless, it
                is sensitive to background variations within the images.</p>
            </li>
            <li>
              <p> Genetic algorithm: an algorithm inspired on the natural
                selection process. Its main advantage is that there is no actual
                need to define a criterion or model to design the system, but
                the model finds a solution itself. Its main problem is that it
                is not an optimal algorithm, so finding the best matching sign
                is not ensured at all.</p>
            </li>
            <li>
              <p> Template matching: this method performs small comparisons
                between the very pixels to find out whether the analyzed image
                is similar enough to one from the stored templates. It is a fast
                algorithm, but sensitive to noise.</p>
            </li>
            <li>
              <p> Decision tree: A machine learning method which constructs
                decision trees during its training, using them in the
                operational stage. It is fast and cheap in computation terms,
                but not agile enough for problems solved in real-time.</p>
            </li>
            <li>
              <p> Support vector machine: this algorithm uses a binary
                classifier and a high abstraction to accomplish the task.
                Despite the fact that it shows good behavior, its results are
                not easily interpreted, so it is seen as a black box that should
                be used cautiously.</p>
            </li>
          </ul>
        </div>
        <br>
      </div>
      <div>
        <hr>
        <h4> Methodology </h4>
        <div>
          <p class="articles"> We will divide the detection and classification
            phases, so different techniques can be applied to each part. For the
            detection, we will use traditional computer vision techniques as HOG
            combined with clustering for image segmentation. The estimation of
            the regions of interest will be made from that information. Once a
            ROI is generated, it will be transferred to a convolutional Neural
            Network for the classification part. For the CNN a pretrained
            network will be used in order to decrease the learning time. It is
            also interesting to split detection and classification because there
            is a larger number of images of traffic signs for the classification
            problem than images for the detection part. This will allow to train
            our model on a wider variety of images. The choice is made also for
            didactic reasons, since the Visio De-Sign team considers it to be
            one of the best ways to apply the knowledge acquired in the Computer
            Vision course of the Master in Automation and Robotics at the UPM.
            Our goal for the detection part of the problem would be something
            like that: </p>
        </div>
      </div>
    </div>
    <div id="team" class="tabcontent" ;="">
      <h3>Team</h3>
      <p class="articles"> In this page, the people involved in the development
        of the algorithm introduce themselves. We also give you some information
        about us to get a little bit closer to the project. These are our lives
        and stories. Nice to meet you! </p>
      <hr>
      <div class="profile_div">
        <h4>Victor Cadix Martín</h4>
        <img src="images/v_profile.jfif" alt="v_profile" class="profile_photos_1" style="width: 200px">
        <h5>Occupation: Technology leader</h5>
        <p style="line-height:25px"> “I am an Industrial Electronics and
          Automatics engineer. Although I was quickly interested in the
          electronics stuff, I really started enjoying this area of engineering
          when I started doing little projects with Arduino. Now I focus more on
          the maths and algorithms that brings "life" to a robot and I am
          currently working on the automatic control of a drone. Something I
          would like, as humans, is that we become an interplanetary species,
          but not because we ran out of resources in our current one.” </p>
      </div>
      <hr>
      <div class="profile_div">
        <h4>Alejandro Casa Rodríguez</h4>
        <img src="images/a_profile.jfif" alt="a_profile" class="profile_photos_1">
        <h5>Occupation: Programming Chief</h5>
        <p style="line-height:25px"> “Aerospace engineer from the Polytechnic
          University of Madrid. Entrepreneur and winner of various competitions
          with ecological proposals, currently co-founder of Faircotech.
          Collaborating with the research group of Numerical Methods and
          Applications to Aerospace Technology in predictive methods in time
          series."ivo </p>
        <blockquote>"Self-education is the only kind of education there is." -K</blockquote>
      </div>
      <hr>
      <div class="profile_div">
        <h4>Hugo de la Quintana Béjar</h4>
        <img src="images/h_profile.jpg" alt="h_profile" class="profile_photos_1">
        <h5>Occupation: Executive Officer</h5>
        <p style="line-height:25px"> “I am a student from the University of
          Alcalá, with a bachelor’s degreein Electronic Engineering and
          Industrial Automatics. I have also a programming title of Android
          apps, given by the EOI. I would like to start working in a job related
          to automatics, and specifically in interface development to improve
          communication between humans and robots in an industrial environment,
          also developing my skills as an application designer and applying
          system control knowledge. When I’m not meshing with job related stuff,
          I love going cycling and hiking to the mountain. Another of my main
          hobbies is traveling to other countries, because I can know about
          other cultures, and that’s a point that combines too well with my
          major passion: beer. I absolutely love finding new tastes and share
          these experiences with my friends.” </p>
        <blockquote>"Nada cambia, si nada cambia" -K</blockquote>
      </div>
      <hr>
      <div class="profile_div">
        <h4>Pablo J. Rosado Junquera</h4>
        <img src="images/p_profile.jpeg" alt="p_profile" class="profile_photos_2">
        <h5>Occupation: Documentation</h5>
        <p style="line-height:25px"> “I am a Materials Engineer and an Energy
          Engineer, with a great passion about mathematics and computer science.
          I have studied programming by my own for a few years, and now I want
          to get a title to prove these skills, and some others I expect to get
          in the course. Talking about job, I ‘just’ hope I find motivation,
          being that achieved through a combination of good salaries, work
          conditions and interesting projects, because this will make me feel
          both important to the company and encouraged to improve every single
          day. To achieve that, I’m willing to seek abroad, as soon as I finish
          my current degree. My free time is always spent with the people I
          care, with simple but lovely afternoons. On the other hand, sometimes
          I enjoy playing online videogames to chill out. I also love traveling
          but I haven´t had yet enough resources to visit a lot of places I
          would like to, so I will have a long to do list in the future.” </p>
        <blockquote>"Ironic dormouse"-A</blockquote>
      </div>
    </div>
    <div id="achievement" class="tabcontent" style="color:#fff" ;="">
      <h3>Achievement</h3>
      <p class="articles">In this section the progress and the new goals that
        the team will reach will be updated.</p>
      <br>
      <hr>
      <h4>Update: 16/09/2019</h4>
      <p class="articles">During the meeting there was discussion about the
        different ideas that each one had about the issue of choosing the
        Benchmark problem. Many ideas have been contributed, but we have finally
        decided on the recognition of traffic signs. Another point of the
        meeting has been the distribution of roles according to the abilities of
        each of the team members, and the result of the debate has been the
        following: Victor as Technology leader, Pablo as responsible for
        Validation, David as responsible for Documentation, Alejandro as
        Programming Chief and Hugo as the Executive Officer. Finally, we have
        established an initial planning to start developing the project. It is a
        very subjective planning that is likely to change over time, but in
        general we will try to follow it.</p>
      <p class="ach_photo_center"><img src="images/planning.png" alt="planning"

          class="achievement_photos_center2" style="height:400px; width:450px;"></p>
      <br>
      <hr>
      <h4>Update: 25/09/2019</h4>
      <p class="articles">The team has been investigating the different
        techniques that can be used for the detection of traffic signals and the
        corresponding methods that will be used to apply them. In addition, one
        of the team members has had to leave it for work reasons, so the roles
        have been modified: from now on, Pablo goes on to take charge of the
        Documentation part, and the Validation part is paused until it is I
        managed to move forward with the implementation of the algorithms.</p>
      <p class="ach_photo_center"><img src="images/bye.jfif" alt="bye" class="achievement_photos_center2"></p>
      <br>
      <hr>
      <h4>Update: 07/10/2019</h4>
      <p class="articles">The web page has been created in broad strokes with
        the minimum contents that will be presented at the University, but that
        will subsequently be developed as new interesting information emerges
        that may be included. Alejandro has designed a very good logo, which
        could be the definitive one, since the rest of the team liked it a lot.</p>
      <p class="ach_photo_center"><img src="images/logo_white.png" alt="logo_white"

          class="achievement_photos_center2" style="height:150px; width:550px;"></p>
      <br>
      <hr>
      <h4>Update: 08/10/2019</h4>
      <p class="articles">Progress has been made in the detection part. To
        obtain the regions of interest, the image has been reconfigured with a
        resolution of 20x26. This decision has been taken because it is the
        minimum amount of information needed to be able to extract the relevant
        regions (where a signal could be) and eliminate uniform areas of color.</p>
      <p class="ach_photo_center"> <img src="images/original.png" alt="Original"

          class="achievement_photos_center2" style="margin-right: 35px"> <img src="images/downsampled.png"

          alt="downsampled" class="achievement_photos_center2"></p>
      <p class="articles">This is an example of blob detection on the 20x26
        image in the blue colorspace.</p>
      <p class="ach_photo_center"><img src="images/heatmap.png" alt="blob detection"

          class="achievement_photos_center2" style="margin-right: 35px"> </p>
      <p class="articles">But, as we can see in the image below, the presence of
        white signals on the road creates a distraction, making the region
        proposal more complicated.</p>
      <p class="ach_photo_center"> <img src="images/white%20paint.png" alt="white paint"

          class="achievement_photos_center2" style="margin-right: 35px"> <img src="images/distractions.png"

          alt="distractions" class="achievement_photos_center2"></p>
      <p class="articles">With this, the white details in the image are
        suppressed and the remaining are the areas where a possible blue sign is
        located. After this operation, the image is normalized again.</p>
      <p class="ach_photo_center"><img src="images/only_blue.png" alt="only_blue"

          class="achievement_photos_center2" style="margin-right: 35px"> </p>
      <hr>
      <h4>Update: 27/12/2019</h4>
      <p class="articles">The team has been unemployed without advancing too
        much in the project due to the beginning of the second bimester classes,
        but the identification part of the traffic signals has begun to develop.
        The problem is based on identifying the ROI previously obtained and
        identifying which signal they belong to. To do this, based on current
        technology, Deep Learning and the tools proposed by it will be used.The
        first tests that have been carried out yield 75% of success, which is a
        good start for a fairly complex task. There is still a lot of work
        ahead.</p>
      <p class="ach_photo_center"><img src="images/deep.jfif" alt="" class="achievement_photos_center2"

          style="height:300px; width:300px;"></p>
      <br>
      <hr>
      <h4>Update: 02/01/2020</h4>
      <p class="articles">Continuing with the identification part, a series of
        algorithms for the treatment of images have been added, which has
        managed to raise the identification success rate to 81%. The tests has
        been that once the size of the entire database is standarized, it is
        passed to the image processing part. In the first iterations it was not
        carried out, but posteriori it was discovered that it was important. The
        equalization of the histogram allows to improve images that have little
        contrast, for example. In this case, the choice has been based on the
        CLAHE (Contrast Limiting Adaptive Histogram Equalization) function.</p>
      <p class="ach_photo_center"> <img src="images/sign1_1.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign1_2.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign1_3.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign1_4.png" alt="" class="achievement_signals"></p>
      <p class="ach_photo_center"> <img src="images/sign2_1.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign2_2.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign2_3.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign2_4.png" alt="" class="achievement_signals"></p>
      <p class="ach_photo_center"> <img src="images/sign3_1.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign3_2.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign3_3.png" alt="" class="achievement_signals"

          style="margin-right: 35px"> <img src="images/sign3_4.png" alt="" class="achievement_signals"></p>
      <p class="articles">The steps that have been taken in image processing has
        been conversion to a single color channel (black and white) images.
        Although it seems counterintuitive that deleting information may improve
        information, this improves network results. Finally, the normalization
        of the images is performed. To do this, what has been done (among the
        many possible options) is to subtract from each image the average of the
        dataset and divide it by the standard deviation. This has allowed us to
        match the weights of all the images and not give more importance to some
        than others.</p>
      <br>
      <hr>
      <h4>Update: 03/01/2020</h4>
      <p class="articles">New tests of the team applying increased data in the
        identification part, which make the success rate has risen to 85%. As
        the database has been artificially augmented, Neural networks need large
        databases to function and more those associated with Deep Learning. That
        is why an increase in the database has been carried out. The original
        size was about 4400 images, and it has been increased to a size of
        20,000 images. This has been done by taking these additional images and
        transforming them by small turns - up to 10 degrees - changes in the
        zoom (15%) and corresponding deformations up to 10% of the image. This
        allows to increase the database increasing its efficiency. However,
        excessive use of this tool or excessive deformations have led to errors
        and overfitting problems, and making the process a bit slower and
        difficult.</p>
      <p class="ach_photo_center"><img src="images/mult_img.png" alt="mult_img"

          class="achievement_photos_center2" style="height:350px; width:350px;"></p>
      <br>
      <hr>
      <h4>Update: 08/01/2020</h4>
      <p class="articles">Once all the previous process has been completed, the
        network is built. This project has progressed recursively, and with each
        iteration various things have been tested until the final configuration.
        Initially the model was built based on a series of 2 convolutional
        layers, along with a dense layer at the end. This model has become more
        complex (without exceeding certain limits, since it worsened the
        behavior) until obtaining the following final configuration.</p>
      <p class="ach_photo_center"><img src="images/final_conf.png" alt="final_conf"

          class="achievement_photos_center2" style="height:250px; width:550px;"></p>
      <p class="articles">Once the images have been detected and treated, the
        identification algorithm, as expected, is capable of processing a larger
        number of images in less times than those previously obtained. The
        success rate also increases, reaching values close to 90%.</p>
      <br>
      <hr>
      <h4>Update: 15/01/2020</h4>
      <p class="articles">After many tests and trials, and making some
        adjustments in the network, it has been possible to reach some indices
        that are around 92-93%.</p>
      <p class="ach_photo_center" style="vertical-align: middle;"> <img src="images/final_graph.png"

          alt="final_graph" class="achievement_photos_center2" style="height:350px; width:550px; margin-right: 35px">
        <img src="images/final_resu.png" alt="final_resu" class="achievement_photos_center2"

          style="height:100px; width:600px; vertical-align: top; margin-top:150px;">
      </p>
      <p class="ach_photo_center"></p>
    </div>
    <div id="about" class="tabcontent" ;="">
      <h3>Credit</h3>
      <p class="articles">Some scientific articles: </p>
      <ol class="articles">
        <li> S. J. Pan and Q. Yang, “A Survey on Transfer Learning,” IEEE Trans.
          Knowl. Data Eng., pp. 1345–1359, 2010. </li>
        <li> M. Mathias, R. Timofte, R. Benenson, and L. Van Gool, “Traffic sign
          recognition 2014; How far are we from the solution?,” 2013 Int. Jt.
          Conf. Neural Networks, pp. 1–8. </li>
        <li> C. Yao, F. Wu, H. Chen, X. Hao, and Y. Shen, “Traffic sign
          recognition using hog-svm and grid search School of Electronic and
          Information Engineering , Beijing Jiaotong University , Beijing ,
          China,”, pp. 962–965, 2014. </li>
        <li> Y. Lai, N. Wang, Y. Yang, and L. Lin, “Traffic Signs Recognition
          and Classification based on Deep Feature Learning,” pp. 622–629, 2018.
        </li>
        <li>M. R-cnn, P. Doll, and R. Girshick, “Mask R-CNN.”</li>
        <li> S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN?: Towards
          Real-Time Object Detection with Region Proposal Networks,” pp. 1–14. </li>
        <li> W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C. Fu, and A.
          C. Berg, “SSD?: Single Shot MultiBox Detector.” </li>
        <li> J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You Only Look
          Once: Unified, Real-Time Object Detection.” </li>
        <li>J. Redmon and A. Farhadi, “YOLO9000: Better, Faster, Stronger.”</li>
        <li> A Novel Genetically Optimized Convolutional Neural Network for
          Traffic Sign Recognition: A New Benchmark on Belgium and Chinese
          Traffic Sign Datasets. </li>
        <li>Deep Learning Traffic Sign Detection, Recognition and Augmentation.</li>
        <li> Total Recall: Understanding Traf?c Signs using Deep Hierarchical
          Convolutional Neural Networks. </li>
      </ol>
    </div>
    <script>
    function openCity(evt, cityName) {
      var i, tabcontent, tablinks;
      tabcontent = document.getElementsByClassName("tabcontent");
      for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
      }
      tablinks = document.getElementsByClassName("tablinks");
      for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
      document.getElementById(cityName).style.display = "block";
      evt.currentTarget.className += " active";
    }
        </script>
    <footer class="foooter"> Visión por Computador - Universidad Politécnica de
      Madrid - 2020 <br>
    </footer>
    <img src="images/logo_etsii.png" alt="logo_etsii" class="footer_photo">
  </body>
</html>
